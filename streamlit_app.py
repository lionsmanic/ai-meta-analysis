import streamlit as st
import google.generativeai as genai
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from pypdf import PdfReader
import io

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="AI-Meta Analysis Pro", layout="wide", page_icon="ğŸ§¬")

st.title("ğŸ§¬ AI-Meta Analysis Pro (Data Extraction Edition)")
st.markdown("### æ•´åˆ PICOã€RoB è©•è®€ã€æ•¸æ“šèƒå–èˆ‡è¦–è¦ºåŒ–çš„å…¨æ–¹ä½å·¥å…·")

# --- è¨­å®š Domain åç¨±å°ç…§è¡¨ ---
DOMAIN_MAPPING = {
    'D1': 'D1 Randomization\n(éš¨æ©Ÿéç¨‹)',
    'D2': 'D2 Deviations\n(ä»‹å…¥åé›¢)',
    'D3': 'D3 Missing Data\n(ç¼ºå¤±æ•¸æ“š)',
    'D4': 'D4 Measurement\n(çµæœæ¸¬é‡)',
    'D5': 'D5 Reporting\n(é¸æ“‡æ€§å ±å‘Š)',
    'Overall': 'Overall Bias\n(æ•´é«”é¢¨éšª)',
    'Reasoning': 'Reasoning\n(è©•è®€ç†ç”±)'
}

# --- Helper Functions (ç¶­æŒåŸæ¨£) ---
def plot_traffic_light(df, title):
    color_map = {'Low': '#2E7D32', 'Some concerns': '#F9A825', 'High': '#C62828'}
    studies = df['Study ID'].tolist()
    domains = ['D1', 'D2', 'D3', 'D4', 'D5', 'Overall']
    plot_labels = ['D1 Randomization', 'D2 Deviations', 'D3 Missing Data', 'D4 Measurement', 'D5 Reporting', 'Overall Bias']
    
    fig, ax = plt.subplots(figsize=(10, len(studies) * 0.8 + 2))
    
    for y, study in enumerate(studies):
        for x, domain in enumerate(domains):
            risk_val = df[df['Study ID'] == study][DOMAIN_MAPPING[domain]].values[0]
            risk = str(risk_val).strip()
            color = '#808080'; symbol = '?'
            if 'Low' in risk: color = color_map['Low']; symbol = '+'
            elif 'High' in risk: color = color_map['High']; symbol = '-'
            elif 'Some' in risk: color = color_map['Some concerns']; symbol = '!'
            
            circle = mpatches.Circle((x, len(studies) - 1 - y), 0.4, color=color)
            ax.add_patch(circle)
            ax.text(x, len(studies) - 1 - y, symbol, ha='center', va='center', color='white', fontweight='bold', fontsize=12)

    ax.set_xlim(-0.5, len(domains) - 0.5); ax.set_ylim(-0.5, len(studies) - 0.5)
    ax.set_xticks(range(len(plot_labels))); ax.set_xticklabels(plot_labels, fontsize=10, fontweight='bold')
    ax.set_yticks(range(len(studies))); ax.set_yticklabels(studies[::-1], fontsize=10)
    for spine in ax.spines.values(): spine.set_visible(False)
    ax.set_title(f"RoB 2.0 Traffic Light Plot: {title}", pad=20, fontsize=14, fontweight='bold')
    patches = [mpatches.Patch(color=v, label=k) for k, v in color_map.items()]
    ax.legend(handles=patches, loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=3, frameon=False)
    return fig

def plot_summary_bar(df, title):
    domains = ['D1', 'D2', 'D3', 'D4', 'D5', 'Overall']
    plot_labels = ['D1 Randomization', 'D2 Deviations', 'D3 Missing Data', 'D4 Measurement', 'D5 Reporting', 'Overall Bias']
    data = []
    for domain in domains:
        col_name = DOMAIN_MAPPING[domain]
        counts = df[col_name].apply(lambda x: 'Low' if 'Low' in str(x) else ('High' if 'High' in str(x) else 'Some concerns')).value_counts()
        total = len(df)
        if total == 0: total = 1
        data.append([(counts.get('Low', 0)/total)*100, (counts.get('Some concerns', 0)/total)*100, (counts.get('High', 0)/total)*100])
        
    df_plot = pd.DataFrame(data, columns=['Low', 'Some concerns', 'High'], index=plot_labels)
    fig, ax = plt.subplots(figsize=(10, 5))
    colors = ['#2E7D32', '#F9A825', '#C62828']
    df_plot.plot(kind='barh', stacked=True, color=colors, ax=ax, width=0.7)
    ax.set_xlim(0, 100); ax.set_xlabel("Percentage of Studies (%)"); ax.set_title(f"Risk of Bias Summary: {title}", fontsize=14, fontweight='bold')
    ax.invert_yaxis(); ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), frameon=False)
    ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)
    return fig

# --- Sidebar: è¨­å®šèˆ‡ API Key ---
with st.sidebar:
    st.header("ğŸ”‘ è¨­å®š")
    if "GOOGLE_API_KEY" in st.secrets:
        api_key = st.secrets["GOOGLE_API_KEY"]
        st.success("âœ… å·²å¾ Secrets è®€å– API Key")
    else:
        api_key = st.text_input("è«‹è¼¸å…¥æ‚¨çš„ Google Gemini API Key", type="password")
    
    st.divider()
    st.header("1. ç ”ç©¶ä¸»é¡Œè¨­å®š")
    topic = st.text_input("ç ”ç©¶ä¸»é¡Œ", "å­å®®å…§è†œç™Œè¡“å¾Œä½¿ç”¨HRTä¹‹å®‰å…¨æ€§")
    
    if api_key:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.5-pro')

# --- åˆ†é åŠŸèƒ½ ---
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ” PICO æª¢ç´¢", "ğŸ¤– AI è©³ç›¡è©•è®€", "ğŸ“Š æ•¸æ“šèƒå–", "ğŸ“ ä½¿ç”¨èªªæ˜"])

# ==========================================
# TAB 1: PICO è¨­å®š
# ==========================================
with tab1:
    st.header("PICO è¨­å®šèˆ‡ PubMed æœå°‹")
    col1, col2 = st.columns(2)
    with col1:
        p_input = st.text_area("P (Patient)", "Endometrial Neoplasms, Survivors")
        i_input = st.text_area("I (Intervention)", "Hormone Replacement Therapy")
    with col2:
        o_input = st.text_area("O (Outcome)", "Recurrence, Menopause Symptoms")
        t_filter = st.checkbox("æ’é™¤ Review æ–‡ç« ", value=True)

    if st.button("ç”Ÿæˆ PubMed æœå°‹å­—ä¸²"):
        def clean(text): return "(" + " OR ".join([f'"{t.strip()}"' for t in text.split(',') if t.strip()]) + ")"
        q_p, q_i, q_o = clean(p_input), clean(i_input), clean(o_input)
        review_filter = ' NOT "Review"[Publication Type]' if t_filter else ""
        final_query = f"{q_p} AND {q_i} AND {q_o}{review_filter}"
        st.code(final_query, language="text")
        st.markdown(f"ğŸ‘‰ [é»æ­¤å‰å¾€ PubMed æœå°‹](https://pubmed.ncbi.nlm.nih.gov/?term={final_query})")

# ==========================================
# TAB 2: AI å…¨è‡ªå‹• RoB è©•è®€
# ==========================================
with tab2:
    st.header("ğŸ¤– AI è‡ªå‹• RoB 2.0 è©•è®€ (å«ç†ç”±)")
    
    if 'rob_results' not in st.session_state: st.session_state.rob_results = None
    if 'uploaded_files' not in st.session_state: st.session_state.uploaded_files = [] # ä¿å­˜ä¸Šå‚³æª”æ¡ˆä»¥ä¾› Tab 3 ä½¿ç”¨

    col_file, col_outcome = st.columns([1, 1])
    with col_file:
        uploaded_files = st.file_uploader("ä¸Šå‚³ PDF æ–‡ç» (æ”¯æ´å¤šæª”)", type="pdf", accept_multiple_files=True, key="rob_uploader")
        if uploaded_files: st.session_state.uploaded_files = uploaded_files # åŒæ­¥åˆ° Session
    with col_outcome:
        primary_outcome = st.text_input("ä¸»è¦ Outcome", "Menopausal symptoms relief", key="rob_primary")
        secondary_outcome = st.text_input("æ¬¡è¦ Outcome", "Cancer recurrence", key="rob_secondary")

    if st.button("ğŸš€ é–‹å§‹ RoB è©•è®€") and api_key and uploaded_files:
        progress_bar = st.progress(0); status_text = st.empty(); table_rows = []
        for i, file in enumerate(uploaded_files):
            status_text.text(f"AI æ­£åœ¨è©³è®€ç¬¬ {i+1} ç¯‡ï¼š{file.name} ... (Gemini 2.5 Pro)")
            try:
                pdf_reader = PdfReader(file)
                text_content = ""
                for page in pdf_reader.pages: text_content += page.extract_text()
            except: continue

            prompt = f"""
            ä½ æ˜¯ä¸€ä½åš´è¬¹çš„å¯¦è­‰é†«å­¸å°ˆå®¶ã€‚è«‹æ ¹æ“š RoB 2.0 æŒ‡å¼•è©•è®€ä»¥ä¸‹æ–‡ç»ã€‚
            **è©•ä¼° Outcomeï¼š** 1. {primary_outcome}, 2. {secondary_outcome}
            **è¼¸å‡ºæ ¼å¼ï¼š** ç´”æ–‡å­—è¡¨æ ¼æ•¸æ“šï¼Œä½¿ç”¨ '|' åˆ†éš”ã€‚æ¯ç¯‡æ–‡ç»é‡å°å…©å€‹ Outcome å„è¼¸å‡ºä¸€è¡Œã€‚
            æ ¼å¼ï¼šStudyID | Outcome | D1 | D2 | D3 | D4 | D5 | Overall | Reasoning
            (D1~Overall åªèƒ½å¡« Low, Some concerns, Highã€‚Reasoning è«‹ç”¨ç¹é«”ä¸­æ–‡è©³è¿°ç†ç”±ã€‚)
            **æ–‡ç»å…§å®¹ï¼š** {text_content[:25000]}
            """
            try:
                response = model.generate_content(prompt)
                for line in response.text.strip().split('\n'):
                    if '|' in line and 'StudyID' not in line:
                        cols = [c.strip() for c in line.split('|')]
                        if len(cols) >= 9: table_rows.append(cols[:9])
            except: pass
            progress_bar.progress((i + 1) / len(uploaded_files))
        
        if table_rows:
            df = pd.DataFrame(table_rows, columns=['Study ID', 'Outcome', 'D1', 'D2', 'D3', 'D4', 'D5', 'Overall', 'Reasoning'])
            st.session_state.rob_results = df.rename(columns=DOMAIN_MAPPING)
            status_text.text("åˆ†æå®Œæˆï¼")

    if st.session_state.rob_results is not None:
        df = st.session_state.rob_results
        st.subheader("ğŸ“‹ è©³ç´°è©•è®€æ•¸æ“šè¡¨"); 
        unique_outcomes = df['Outcome'].unique()
        for outcome in unique_outcomes:
            st.markdown(f"#### ğŸ“Œ Outcome: {outcome}")
            subset_df = df[df['Outcome'] == outcome].reset_index(drop=True).drop(columns=['Outcome'])
            st.dataframe(subset_df, use_container_width=True); st.markdown("---")

        st.subheader("ğŸš¦ RoB 2.0 è¦–è¦ºåŒ–")
        sel_outcome = st.selectbox("é¸æ“‡ Outcome ç¹ªåœ–:", unique_outcomes, key="rob_viz_outcome")
        viz_df = df[df['Outcome'] == sel_outcome]
        if not viz_df.empty:
            c1, c2 = st.columns(2)
            with c1: st.pyplot(plot_traffic_light(viz_df, sel_outcome))
            with c2: st.pyplot(plot_summary_bar(viz_df, sel_outcome))

# ==========================================
# TAB 3: æ•¸æ“šèƒå– (NEW FEATURE)
# ==========================================
with tab3:
    st.header("ğŸ“Š æ•¸æ“šèƒå– (Data Extraction)")
    st.markdown("é‡å°é¸å®šçš„ Outcomeï¼Œè‡ªå‹•èƒå– Intervention (Tx) èˆ‡ Control (Ctrl) çš„çµ±è¨ˆæ•¸å€¼ï¼Œä»¥ä¾›æ£®æ—åœ–ç¹ªè£½ä½¿ç”¨ã€‚")
    
    if 'data_extract_results' not in st.session_state: st.session_state.data_extract_results = None
    
    # ä½¿ç”¨è€…ä»‹é¢
    col_ex_outcome, col_ex_type = st.columns([2, 1])
    with col_ex_outcome:
        # è®“ä½¿ç”¨è€…è¼¸å…¥æƒ³è¦èƒå–çš„ Outcome (é è¨­å¸¶å…¥ RoB çš„ä¸»è¦ outcome)
        target_outcome = st.text_input("æ¬²èƒå–çš„ Outcome åç¨±", "Menopausal symptoms relief", key="extract_outcome")
    with col_ex_type:
        # é¸æ“‡æ•¸æ“šå‹æ…‹
        data_type = st.radio("æ•¸æ“šå‹æ…‹ (Data Type)", 
                             ["äºŒå…ƒæ•¸æ“š (Binary: Events/Total)", "é€£çºŒæ•¸æ“š (Continuous: Mean/SD)"],
                             help="äºŒå…ƒæ•¸æ“šç”¨æ–¼è¨ˆç®— Risk Ratio / Odds Ratioï¼›é€£çºŒæ•¸æ“šç”¨æ–¼è¨ˆç®— Mean Difference")

    if st.button("ğŸ” é–‹å§‹æ•¸æ“šèƒå–") and api_key and st.session_state.uploaded_files:
        progress_bar = st.progress(0); status_text = st.empty(); extract_rows = []
        files = st.session_state.uploaded_files
        
        for i, file in enumerate(files):
            status_text.text(f"æ­£åœ¨æœå°‹æ•¸æ“šï¼š{file.name} ...")
            try:
                pdf_reader = PdfReader(file)
                text_content = ""
                for page in pdf_reader.pages: text_content += page.extract_text()
            except: continue

            # æ ¹æ“šæ•¸æ“šå‹æ…‹æ§‹å»ºä¸åŒçš„ Prompt
            if "Binary" in data_type:
                # äºŒå…ƒæ•¸æ“š Prompt
                prompt = f"""
                ä½ æ˜¯ä¸€ä½é†«å­¸æ•¸æ“šåˆ†æå¸«ã€‚è«‹é–±è®€ä»¥ä¸‹æ–‡ç»ï¼Œé‡å° Outcome: "{target_outcome}" æ‰¾å‡ºå¯¦é©—çµ„ (Intervention/Tx) èˆ‡å°ç…§çµ„ (Control) çš„æ•¸æ“šã€‚
                
                **ç›®æ¨™æ•¸æ“šå‹æ…‹ï¼šBinary (äºŒå…ƒæ•¸æ“š)**
                æˆ‘éœ€è¦ï¼š
                1. Tx_Events: å¯¦é©—çµ„ç™¼ç”Ÿäº‹ä»¶çš„äººæ•¸
                2. Tx_Total: å¯¦é©—çµ„ç¸½äººæ•¸
                3. Ctrl_Events: å°ç…§çµ„ç™¼ç”Ÿäº‹ä»¶çš„äººæ•¸
                4. Ctrl_Total: å°ç…§çµ„ç¸½äººæ•¸
                
                **è¼¸å‡ºæ ¼å¼åš´æ ¼è¦æ±‚ï¼š**
                è«‹è¼¸å‡ºå–®è¡Œç´”æ–‡å­—æ•¸æ“šï¼Œä½¿ç”¨ '|' åˆ†éš”ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
                StudyID | Tx_Events | Tx_Total | Ctrl_Events | Ctrl_Total
                (è‹¥æ–‡ä¸­æœªæ˜ç¢ºæåŠæŸæ•¸å€¼ï¼Œè«‹å¡«å¯« NA)

                **æ–‡ç»å…§å®¹ï¼š** {text_content[:25000]}
                """
                cols_schema = ['Study ID', 'Tx Events', 'Tx Total', 'Ctrl Events', 'Ctrl Total']
            else:
                # é€£çºŒæ•¸æ“š Prompt
                prompt = f"""
                ä½ æ˜¯ä¸€ä½é†«å­¸æ•¸æ“šåˆ†æå¸«ã€‚è«‹é–±è®€ä»¥ä¸‹æ–‡ç»ï¼Œé‡å° Outcome: "{target_outcome}" æ‰¾å‡ºå¯¦é©—çµ„ (Intervention/Tx) èˆ‡å°ç…§çµ„ (Control) çš„æ•¸æ“šã€‚
                
                **ç›®æ¨™æ•¸æ“šå‹æ…‹ï¼šContinuous (é€£çºŒæ•¸æ“š)**
                æˆ‘éœ€è¦ï¼š
                1. Tx_Mean: å¯¦é©—çµ„å¹³å‡å€¼
                2. Tx_SD: å¯¦é©—çµ„æ¨™æº–å·® (Standard Deviation)
                3. Tx_Total: å¯¦é©—çµ„ç¸½äººæ•¸
                4. Ctrl_Mean: å°ç…§çµ„å¹³å‡å€¼
                5. Ctrl_SD: å°ç…§çµ„æ¨™æº–å·®
                6. Ctrl_Total: å°ç…§çµ„ç¸½äººæ•¸
                
                (æ³¨æ„ï¼šè‹¥æ–‡ä¸­çµ¦çš„æ˜¯ SE (Standard Error)ï¼Œè«‹å˜—è©¦è½‰æ›ç‚º SDï¼Œæˆ–ç›´æ¥å¡«å¯«æ–‡ä¸­æ•¸å€¼ä¸¦æ¨™è¨»ã€‚è‹¥æ‰¾ä¸åˆ°ï¼Œå¡« NA)

                **è¼¸å‡ºæ ¼å¼åš´æ ¼è¦æ±‚ï¼š**
                è«‹è¼¸å‡ºå–®è¡Œç´”æ–‡å­—æ•¸æ“šï¼Œä½¿ç”¨ '|' åˆ†éš”ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
                StudyID | Tx_Mean | Tx_SD | Tx_Total | Ctrl_Mean | Ctrl_SD | Ctrl_Total

                **æ–‡ç»å…§å®¹ï¼š** {text_content[:25000]}
                """
                cols_schema = ['Study ID', 'Tx Mean', 'Tx SD', 'Tx Total', 'Ctrl Mean', 'Ctrl SD', 'Ctrl Total']

            try:
                response = model.generate_content(prompt)
                lines = response.text.strip().split('\n')
                for line in lines:
                    if '|' in line and 'StudyID' not in line: # éæ¿¾è¡¨é ­
                        cols = [c.strip() for c in line.split('|')]
                        # æª¢æŸ¥æ¬„ä½æ•¸é‡æ˜¯å¦ç¬¦åˆé æœŸ
                        if len(cols) == len(cols_schema):
                            extract_rows.append(cols)
            except: pass
            progress_bar.progress((i + 1) / len(files))

        if extract_rows:
            df_extract = pd.DataFrame(extract_rows, columns=cols_schema)
            st.session_state.data_extract_results = df_extract
            status_text.text("æ•¸æ“šèƒå–å®Œæˆï¼")
        else:
            st.error("AI æœªèƒ½æ‰¾åˆ°ç›¸é—œæ•¸æ“šï¼Œè«‹ç¢ºèª Outcome åç¨±æ˜¯å¦èˆ‡æ–‡å…§ä¸€è‡´ã€‚")

    # é¡¯ç¤ºçµæœ
    if st.session_state.data_extract_results is not None:
        st.subheader(f"ğŸ“Š èƒå–çµæœè¡¨: {target_outcome}")
        
        # æ ¹æ“šæ•¸æ“šå‹æ…‹é¡¯ç¤ºä¸åŒçš„èªªæ˜
        if "Binary" in data_type:
            st.info("ğŸ’¡ æ­¤è¡¨æ ¼é©ç”¨æ–¼ Risk Ratio (RR) æˆ– Odds Ratio (OR) åˆ†æã€‚")
        else:
            st.info("ğŸ’¡ æ­¤è¡¨æ ¼é©ç”¨æ–¼ Mean Difference (MD) æˆ– SMD åˆ†æã€‚")
            
        st.dataframe(st.session_state.data_extract_results, use_container_width=True)
        
        # æä¾› CSV ä¸‹è¼‰æŒ‰éˆ• (æ–¹ä¾¿å¾ŒçºŒè·‘ R æˆ– RevMan)
        csv = st.session_state.data_extract_results.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ ä¸‹è¼‰ Excel/CSV æª”", data=csv, file_name=f"extraction_{target_outcome}.csv", mime="text/csv")
    
    elif not st.session_state.uploaded_files:
        st.warning("âš ï¸ è«‹å…ˆè‡³ã€ŒAI è©³ç›¡è©•è®€ã€é ç±¤ä¸Šå‚³ PDF æ–‡ç»ã€‚")

# ==========================================
# TAB 4: ä½¿ç”¨èªªæ˜
# ==========================================
with tab4:
    st.markdown("""
    ### ä½¿ç”¨æŒ‡å—
    1. **RoB è©•è®€**ï¼šè‡³ç¬¬äºŒåˆ†é ä¸Šå‚³ PDFï¼Œé€²è¡Œå“è³ªè©•è®€ã€‚
    2. **æ•¸æ“šèƒå– (NEW!)**ï¼š
       - åˆ‡æ›è‡³ç¬¬ä¸‰åˆ†é ã€‚
       - è¼¸å…¥æ‚¨æƒ³æŠ“å–çš„ Outcome åç¨± (ä¾‹å¦‚ï¼šPain Score)ã€‚
       - é¸æ“‡æ•¸æ“šé¡å‹ (äºŒå…ƒ Binary æˆ– é€£çºŒ Continuous)ã€‚
       - é»æ“Šèƒå–ï¼ŒAI æœƒè‡ªå‹•æƒææ‰€æœ‰å·²ä¸Šå‚³çš„ PDFã€‚
       - çµæœå¯ä¸‹è¼‰ç‚º CSVï¼Œç›´æ¥ç”¨æ–¼ Meta-analysis è»Ÿé«”ã€‚
    """)
