import streamlit as st
import google.generativeai as genai
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import matplotlib.gridspec as gridspec
from pypdf import PdfReader
import scipy.stats as stats
import io

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="AI-Meta Analysis Pro", layout="wide", page_icon="ğŸ§¬")

st.title("ğŸ§¬ AI-Meta Analysis Pro (Fixed & Polished)")
st.markdown("### æ•´åˆ PICOã€RoB è©•è®€ã€æ•¸æ“šèƒå–èˆ‡ **æœŸåˆŠç´šçµ±è¨ˆåœ–è¡¨** çš„å…¨æ–¹ä½å·¥å…·")

# --- è¨­å®š Domain åç¨±å°ç…§è¡¨ ---
DOMAIN_MAPPING = {
    'D1': 'D1 Randomization\n(éš¨æ©Ÿéç¨‹)',
    'D2': 'D2 Deviations\n(ä»‹å…¥åé›¢)',
    'D3': 'D3 Missing Data\n(ç¼ºå¤±æ•¸æ“š)',
    'D4': 'D4 Measurement\n(çµæœæ¸¬é‡)',
    'D5': 'D5 Reporting\n(é¸æ“‡æ€§å ±å‘Š)',
    'Overall': 'Overall Bias\n(æ•´é«”é¢¨éšª)',
    'Reasoning': 'Reasoning\n(è©•è®€ç†ç”±)'
}

# --- çµ±è¨ˆé‹ç®—æ ¸å¿ƒ ---
class MetaAnalysisEngine:
    def __init__(self, df, data_type):
        self.df = df.copy().reset_index(drop=True)
        self.data_type = data_type
        self.results = {}
        self.influence_df = pd.DataFrame() # åˆå§‹åŒ–
        self._calculate_effect_sizes()
        self._run_random_effects()
        self._calculate_influence_diagnostics()

    def _calculate_effect_sizes(self):
        cols_to_numeric = [c for c in self.df.columns if c not in ['Study ID', 'Population', 'Tx Details', 'Ctrl Details']]
        for c in cols_to_numeric:
            self.df[c] = pd.to_numeric(self.df[c], errors='coerce')
        self.df = self.df.dropna(subset=cols_to_numeric).reset_index(drop=True)

        if "Binary" in self.data_type:
            a = self.df['Tx Events'] + 0.5; n1 = self.df['Tx Total'] + 0.5
            c = self.df['Ctrl Events'] + 0.5; n2 = self.df['Ctrl Total'] + 0.5
            self.df['TE'] = np.log((a/n1) / (c/n2))
            self.df['seTE'] = np.sqrt(1/a - 1/n1 + 1/c - 1/n2)
            self.effect_label = "Risk Ratio (Log Scale)"
            self.measure = "RR"
        else:
            n1 = self.df['Tx Total']; n2 = self.df['Ctrl Total']
            m1 = self.df['Tx Mean']; m2 = self.df['Ctrl Mean']
            sd1 = self.df['Tx SD']; sd2 = self.df['Ctrl SD']
            md = m1 - m2
            sd_pooled = np.sqrt(((n1 - 1) * sd1**2 + (n2 - 1) * sd2**2) / (n1 + n2 - 2))
            self.df['TE'] = md / sd_pooled
            self.df['seTE'] = np.sqrt((n1 + n2) / (n1 * n2) + (self.df['TE']**2) / (2 * (n1 + n2)))
            self.effect_label = "Std. Mean Difference"
            self.measure = "SMD"
            
        self.df['lower'] = self.df['TE'] - 1.96 * self.df['seTE']
        self.df['upper'] = self.df['TE'] + 1.96 * self.df['seTE']

    def _run_random_effects(self):
        k = len(self.df)
        if k <= 1: return
        w_fixed = 1 / (self.df['seTE']**2)
        te_fixed = np.sum(w_fixed * self.df['TE']) / np.sum(w_fixed)
        Q = np.sum(w_fixed * (self.df['TE'] - te_fixed)**2)
        df_Q = k - 1
        C = np.sum(w_fixed) - np.sum(w_fixed**2) / np.sum(w_fixed)
        tau2 = max(0, (Q - df_Q) / C) if C > 0 else 0
        w_random = 1 / (self.df['seTE']**2 + tau2)
        te_random = np.sum(w_random * self.df['TE']) / np.sum(w_random)
        se_random = np.sqrt(1 / np.sum(w_random))
        self.results = {
            'TE_pooled': te_random, 'seTE_pooled': se_random,
            'lower_pooled': te_random - 1.96*se_random, 'upper_pooled': te_random + 1.96*se_random,
            'tau2': tau2, 'Q': Q, 'I2': max(0, (Q - df_Q) / Q) * 100 if Q > 0 else 0,
            'weights_raw': w_random
        }
        self.df['weight'] = (w_random / np.sum(w_random)) * 100

    def _calculate_influence_diagnostics(self):
        k = len(self.df); res = self.results
        if k <= 1: return
        
        original_te = res['TE_pooled']; original_tau2 = res['tau2']
        influence_data = []
        for i in self.df.index:
            subset = self.df.drop(i)
            w_fixed = 1 / (subset['seTE']**2)
            te_fixed = np.sum(w_fixed * subset['TE']) / np.sum(w_fixed)
            Q_del = np.sum(w_fixed * (subset['TE'] - te_fixed)**2)
            C_del = np.sum(w_fixed) - np.sum(w_fixed**2) / np.sum(w_fixed)
            tau2_del = max(0, (Q_del - (k - 2)) / C_del) if C_del > 0 else 0
            w_random = 1 / (subset['seTE']**2 + tau2_del)
            te_del = np.sum(w_random * subset['TE']) / np.sum(w_random)
            se_del = np.sqrt(1 / np.sum(w_random))
            
            hat = self.df.loc[i, 'weight'] / 100.0
            resid = self.df.loc[i, 'TE'] - original_te
            var_resid = self.df.loc[i, 'seTE']**2 + original_tau2
            rstudent = resid / np.sqrt(var_resid)
            dffits = np.sqrt(hat / (1 - hat)) * rstudent if hat < 1 else 0
            cook_d = (rstudent**2 * hat) / (1 - hat) if hat < 1 else 0
            cov_r = (se_del**2) / (res['seTE_pooled']**2)

            influence_data.append({
                'Study ID': self.df.loc[i, 'Study ID'],
                'rstudent': rstudent, 'dffits': dffits, 'cook.d': cook_d, 'cov.r': cov_r,
                'tau2.del': tau2_del, 'QE.del': Q_del, 'hat': hat, 'weight': self.df.loc[i, 'weight'],
                'TE.del': te_del, 'lower.del': te_del - 1.96 * se_del, 'upper.del': te_del + 1.96 * se_del
            })
        self.influence_df = pd.DataFrame(influence_data)

    # ğŸš€ ä¿®å¾©ï¼šè£œä¸Šé€™å€‹é—œéµå‡½å¼ï¼Œè§£æ±º AttributeError
    def get_influence_diagnostics(self):
        return self.influence_df

# --- ç¹ªåœ–å‡½å¼ (å„ªåŒ–ç‰ˆé¢é…ç½®) ---

def plot_forest_professional(ma_engine):
    df = ma_engine.df
    res = ma_engine.results
    measure = ma_engine.measure
    is_binary = "Binary" in ma_engine.data_type
    
    # èª¿æ•´è§£æåº¦èˆ‡å­—é«”
    plt.rcParams.update({'font.size': 11, 'figure.dpi': 200}) 
    
    n_studies = len(df)
    # å¢åŠ é«˜åº¦å€ç‡ï¼Œé¿å…å£“æ‰ (æ¯è¡Œ 0.6 inch + 3 inch header/footer)
    fig_height = n_studies * 0.6 + 3
    
    # GridSpec: [Data Table] [Plot] [Stats Table]
    # èª¿æ•´ width_ratios è®“ä¸­é–“åœ–è¡¨å€æ›´å¯¬ä¸€é»ï¼Œå·¦å³æ›´ç·Šæ¹Š
    fig = plt.figure(figsize=(15, fig_height))
    gs = gridspec.GridSpec(1, 3, width_ratios=[2.5, 2, 1.5], wspace=0.05)
    
    ax_left = plt.subplot(gs[0])
    ax_mid = plt.subplot(gs[1])
    ax_right = plt.subplot(gs[2])
    
    # è¨­å®š Y è»¸ (0 åœ¨æœ€ä¸Šæ–¹)
    n_rows = n_studies + 3 # Header + Studies + Footer
    for ax in [ax_left, ax_mid, ax_right]:
        ax.set_ylim(0, n_rows)
        ax.axis('off')

    # --- 1. å·¦å´æ•¸æ“šæ¬„ (é å·¦å°é½Šå„ªåŒ–) ---
    y_header = n_rows - 0.5
    ax_left.text(0, y_header, "Study", fontweight='bold', ha='left', va='center')
    
    # ä½¿ç”¨å›ºå®š X åº§æ¨™ç¢ºä¿å°é½Š
    x_col1 = 0.65
    x_col2 = 0.85
    
    if is_binary:
        ax_left.text(x_col1, y_header, "Tx\n(n/N)", fontweight='bold', ha='center', va='center')
        ax_left.text(x_col2, y_header, "Ctrl\n(n/N)", fontweight='bold', ha='center', va='center')
        
        for i, row in df.iterrows():
            y = n_rows - 1.5 - i
            ax_left.text(0, y, str(row['Study ID']), ha='left', va='center')
            ax_left.text(x_col1, y, f"{int(row['Tx Events'])}/{int(row['Tx Total'])}", ha='center', va='center')
            ax_left.text(x_col2, y, f"{int(row['Ctrl Events'])}/{int(row['Ctrl Total'])}", ha='center', va='center')
            
        # Pooled Row
        ax_left.text(0, 0.5, "Random Effects Model", fontweight='bold', ha='left', va='center')
        ax_left.text(x_col1, 0.5, str(int(df['Tx Total'].sum())), fontweight='bold', ha='center', va='center')
        ax_left.text(x_col2, 0.5, str(int(df['Ctrl Total'].sum())), fontweight='bold', ha='center', va='center')
        
    else: # Continuous
        ax_left.text(x_col1, y_header, "Tx\n(Mean/SD)", fontweight='bold', ha='center', va='center')
        ax_left.text(x_col2, y_header, "Ctrl\n(Mean/SD)", fontweight='bold', ha='center', va='center')
        for i, row in df.iterrows():
            y = n_rows - 1.5 - i
            ax_left.text(0, y, str(row['Study ID']), ha='left', va='center')
            ax_left.text(x_col1, y, f"{row['Tx Mean']:.1f}/{row['Tx SD']:.1f}", ha='center', va='center')
            ax_left.text(x_col2, y, f"{row['Ctrl Mean']:.1f}/{row['Ctrl SD']:.1f}", ha='center', va='center')
        ax_left.text(0, 0.5, "Random Effects Model", fontweight='bold', ha='left', va='center')

    # åˆ†éš”ç·š (Header)
    ax_left.plot([0, 1], [y_header-0.4, y_header-0.4], color='black', linewidth=1, transform=ax_left.transAxes, clip_on=False)

    # --- 2. ä¸­é–“æ£®æ—åœ– ---
    ax_mid.axis('on')
    ax_mid.spines['top'].set_visible(False)
    ax_mid.spines['left'].set_visible(False)
    ax_mid.spines['right'].set_visible(False)
    ax_mid.get_yaxis().set_visible(False) # éš±è— Y è»¸åˆ»åº¦
    ax_mid.set_ylim(0, n_rows) # ç¢ºä¿èˆ‡æ–‡å­—å°é½Š
    
    if measure == "RR":
        vals = np.exp(df['TE']); lows = np.exp(df['lower']); ups = np.exp(df['upper'])
        pool_val = np.exp(res['TE_pooled']); pool_low = np.exp(res['lower_pooled']); pool_up = np.exp(res['upper_pooled'])
        ax_mid.set_xscale('log')
        center = 1.0
    else:
        vals, lows, ups = df['TE'], df['lower'], df['upper']
        pool_val, pool_low, pool_up = res['TE_pooled'], res['lower_pooled'], res['upper_pooled']
        center = 0.0
        
    # Plot Rows
    for i, row in df.iterrows():
        y = n_rows - 1.5 - i
        ax_mid.plot([lows[i], ups[i]], [y, y], color='black', linewidth=1.2)
        ax_mid.plot(vals[i], y, 's', color='gray', markersize=6)

    # Center Line
    ax_mid.axvline(x=center, color='black', linewidth=0.8)
    
    # Pooled Diamond
    y_pool = 0.5
    diamond_x = [pool_low, pool_val, pool_up, pool_val]
    diamond_y = [y_pool, y_pool + 0.25, y_pool, y_pool - 0.25]
    ax_mid.fill(diamond_x, diamond_y, color='red', alpha=0.6)
    
    # Heterogeneity Text (Bottom)
    het_text = f"Heterogeneity: $I^2$={res['I2']:.1f}%, $\\tau^2$={res['tau2']:.3f}"
    ax_mid.set_xlabel(f"{measure} (95% CI)\n\n{het_text}")

    # --- 3. å³å´çµ±è¨ˆæ¬„ ---
    ax_right.text(0.2, y_header, f"{measure}", fontweight='bold', ha='center', va='center')
    ax_right.text(0.6, y_header, "95% CI", fontweight='bold', ha='center', va='center')
    ax_right.text(0.95, y_header, "Weight", fontweight='bold', ha='center', va='center')
    
    for i, row in df.iterrows():
        y = n_rows - 1.5 - i
        val = np.exp(row['TE']) if measure == "RR" else row['TE']
        low = np.exp(row['lower']) if measure == "RR" else row['lower']
        up = np.exp(row['upper']) if measure == "RR" else row['upper']
        
        ax_right.text(0.2, y, f"{val:.2f}", ha='center', va='center')
        ax_right.text(0.6, y, f"[{low:.2f}; {up:.2f}]", ha='center', va='center')
        ax_right.text(0.95, y, f"{row['weight']:.1f}%", ha='center', va='center')
        
    # Pooled Stats
    ax_right.text(0.2, 0.5, f"{pool_val:.2f}", fontweight='bold', ha='center', va='center')
    ax_right.text(0.6, 0.5, f"[{pool_low:.2f}; {pool_up:.2f}]", fontweight='bold', ha='center', va='center')
    ax_right.text(0.95, 0.5, "100.0%", fontweight='bold', ha='center', va='center')
    
    # Header Line
    ax_right.plot([0, 1], [y_header-0.4, y_header-0.4], color='black', linewidth=1, transform=ax_right.transAxes, clip_on=False)

    plt.tight_layout()
    return fig

def plot_leave_one_out_professional(ma_engine):
    inf_df = ma_engine.influence_df
    measure = ma_engine.measure
    res = ma_engine.results
    
    plt.rcParams.update({'font.size': 11, 'figure.dpi': 200})
    n_studies = len(inf_df)
    fig_height = n_studies * 0.6 + 2
    
    # GridSpec: [Text] [Plot] [Stats]
    fig = plt.figure(figsize=(14, fig_height))
    gs = gridspec.GridSpec(1, 3, width_ratios=[2, 2, 1.2], wspace=0.05)
    
    ax_left = plt.subplot(gs[0]); ax_mid = plt.subplot(gs[1]); ax_right = plt.subplot(gs[2])
    n_rows = n_studies + 2
    
    for ax in [ax_left, ax_mid, ax_right]: 
        ax.set_ylim(0, n_rows)
        ax.axis('off')
    
    # Header
    y_header = n_rows - 0.5
    ax_left.text(0, y_header, "Study Omitted", fontweight='bold', ha='left')
    ax_right.text(0.5, y_header, f"{measure} (95% CI)", fontweight='bold', ha='center')
    
    # Data Prep
    if measure == "RR":
        vals = np.exp(inf_df['TE.del']); lows = np.exp(inf_df['lower.del']); ups = np.exp(inf_df['upper.del'])
        orig_val = np.exp(res['TE_pooled']); orig_low = np.exp(res['lower_pooled']); orig_up = np.exp(res['upper_pooled'])
        center = 1.0
        ax_mid.set_xscale('log')
    else:
        vals, lows, ups = inf_df['TE.del'], inf_df['lower.del'], inf_df['upper.del']
        orig_val = res['TE_pooled']; orig_low = res['lower_pooled']; orig_up = res['upper_pooled']
        center = 0.0
        
    ax_mid.axis('on'); ax_mid.spines['top'].set_visible(False); ax_mid.spines['left'].set_visible(False); ax_mid.spines['right'].set_visible(False); ax_mid.get_yaxis().set_visible(False)
    ax_mid.axvline(x=center, color='black', linewidth=0.8)
    ax_mid.set_xlabel(f"Leave-One-Out {measure}")

    # Plot Rows
    for i, row in inf_df.iterrows():
        y = n_rows - 1.5 - i
        ax_left.text(0, y, f"Omitting {row['Study ID']}", ha='left', va='center')
        
        ax_mid.plot([lows[i], ups[i]], [y, y], color='black', linewidth=1.2)
        ax_mid.plot(vals[i], y, 's', color='gray', markersize=6)
        
        txt = f"{vals[i]:.2f} [{lows[i]:.2f}; {ups[i]:.2f}]"
        ax_right.text(0.5, y, txt, ha='center', va='center')
        
    # Original Pooled
    y_pool = 0.5
    diamond_x = [orig_low, orig_val, orig_up, orig_val]
    diamond_y = [y_pool, y_pool+0.25, y_pool, y_pool-0.25]
    ax_mid.fill(diamond_x, diamond_y, color='red', alpha=0.6)
    ax_left.text(0, y_pool, "All Studies Included", fontweight='bold', ha='left', va='center')
    ax_right.text(0.5, y_pool, f"{orig_val:.2f} [{orig_low:.2f}; {orig_up:.2f}]", fontweight='bold', ha='center', va='center')
    
    # Header Lines
    for ax in [ax_left, ax_right]:
        ax.plot([0, 1], [y_header-0.4, y_header-0.4], color='black', linewidth=1, transform=ax.transAxes, clip_on=False)
    
    plt.tight_layout()
    return fig

def plot_funnel(ma_engine):
    df = ma_engine.df
    res = ma_engine.results
    te_pooled = res['TE_pooled']
    plt.rcParams.update({'font.size': 10, 'figure.dpi': 150})
    fig, ax = plt.subplots(figsize=(6, 5))
    ax.scatter(df['TE'], df['seTE'], color='blue', alpha=0.6, edgecolors='k', zorder=3)
    max_se = max(df['seTE']) * 1.1
    x_triangle = [te_pooled - 1.96*max_se, te_pooled, te_pooled + 1.96*max_se]
    y_triangle = [max_se, 0, max_se]
    ax.fill(x_triangle, y_triangle, color='gray', alpha=0.1, zorder=0)
    ax.plot([te_pooled, te_pooled - 1.96*max_se], [0, max_se], color='gray', linestyle='--', linewidth=1)
    ax.plot([te_pooled, te_pooled + 1.96*max_se], [0, max_se], color='gray', linestyle='--', linewidth=1)
    ax.axvline(x=te_pooled, color='red', linestyle='--', linewidth=1)
    ax.set_ylim(max_se, 0)
    ax.set_ylabel("Standard Error")
    ax.set_xlabel(ma_engine.effect_label)
    ax.set_title("Funnel Plot", fontweight='bold')
    return fig

def plot_baujat(diag_df):
    plt.rcParams.update({'font.size': 10, 'figure.dpi': 150})
    fig, ax = plt.subplots(figsize=(6, 5))
    x_val = diag_df['rstudent'] ** 2 
    y_val = abs(diag_df['TE'] - diag_df['TE.del'])
    ax.scatter(x_val, y_val, color='purple', s=100, alpha=0.7)
    for i, txt in enumerate(diag_df['Study ID']):
        ax.annotate(txt, (x_val[i], y_val[i]), xytext=(5, 5), textcoords='offset points', fontsize=9)
    ax.set_xlabel("Contribution to Heterogeneity")
    ax.set_ylabel("Influence on Pooled Result")
    ax.set_title("Baujat Plot", fontweight='bold')
    ax.grid(True, linestyle='--', alpha=0.5)
    return fig

def plot_influence_diagnostics_grid(ma_engine):
    df = ma_engine.influence_df
    k = len(df); x = np.arange(1, k + 1)
    metrics = [('rstudent', 'Studentized Residuals', [-2, 2]), ('dffits', 'DFFITS', [2 * np.sqrt(2/k)]), 
               ('cook.d', "Cook's Distance", [4/k]), ('cov.r', 'Covariance Ratio', [1]),
               ('tau2.del', 'Leave-One-Out TauÂ²', [ma_engine.results['tau2']]), ('QE.del', 'Leave-One-Out Q', [ma_engine.results['Q'] - (k-1)]), 
               ('hat', 'Hat Values (Leverage)', [2/k]), ('weight', 'Weight (%)', [100/k])]
    plt.rcParams.update({'font.size': 9, 'figure.dpi': 150}) 
    fig, axes = plt.subplots(4, 2, figsize=(12, 16))
    axes = axes.flatten()
    for i, (col, title, hlines) in enumerate(metrics):
        ax = axes[i]; vals = df[col]
        ax.plot(x, vals, 'o-', color='black', markerfacecolor='gray', markersize=5, linewidth=1)
        max_idx = np.argmax(np.abs(vals)); ax.plot(x[max_idx], vals[max_idx], 'o', color='red', markersize=6)
        for h in hlines: ax.axhline(h, linestyle='--', color='black', linewidth=0.8)
        ax.set_title(title, fontweight='bold'); ax.set_xticks(x); ax.set_xticklabels(range(1, k+1))
    plt.tight_layout()
    return fig

# --- Helper Functions (Traffic Light & Summary) ---
def plot_traffic_light(df, title):
    color_map = {'Low': '#2E7D32', 'Some concerns': '#F9A825', 'High': '#C62828'}
    studies = df['Study ID'].tolist()
    domains = ['D1', 'D2', 'D3', 'D4', 'D5', 'Overall']
    plot_labels = ['D1 Randomization', 'D2 Deviations', 'D3 Missing Data', 'D4 Measurement', 'D5 Reporting', 'Overall Bias']
    fig, ax = plt.subplots(figsize=(10, len(studies) * 0.8 + 2))
    for y, study in enumerate(studies):
        for x, domain in enumerate(domains):
            risk_val = df[df['Study ID'] == study][DOMAIN_MAPPING[domain]].values[0]
            risk = str(risk_val).strip()
            color = '#808080'; symbol = '?'
            if 'Low' in risk: color = color_map['Low']; symbol = '+'
            elif 'High' in risk: color = color_map['High']; symbol = '-'
            elif 'Some' in risk: color = color_map['Some concerns']; symbol = '!'
            circle = mpatches.Circle((x, len(studies) - 1 - y), 0.4, color=color)
            ax.add_patch(circle)
            ax.text(x, len(studies) - 1 - y, symbol, ha='center', va='center', color='white', fontweight='bold', fontsize=12)
    ax.set_xlim(-0.5, len(domains) - 0.5); ax.set_ylim(-0.5, len(studies) - 0.5)
    ax.set_xticks(range(len(plot_labels))); ax.set_xticklabels(plot_labels, fontsize=10, fontweight='bold')
    ax.set_yticks(range(len(studies))); ax.set_yticklabels(studies[::-1], fontsize=10)
    for spine in ax.spines.values(): spine.set_visible(False)
    ax.set_title(f"RoB 2.0 Traffic Light Plot: {title}", pad=20, fontsize=14, fontweight='bold')
    patches = [mpatches.Patch(color=v, label=k) for k, v in color_map.items()]
    ax.legend(handles=patches, loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=3, frameon=False)
    return fig

def plot_summary_bar(df, title):
    domains = ['D1', 'D2', 'D3', 'D4', 'D5', 'Overall']
    plot_labels = ['D1 Randomization', 'D2 Deviations', 'D3 Missing Data', 'D4 Measurement', 'D5 Reporting', 'Overall Bias']
    data = []
    for domain in domains:
        col_name = DOMAIN_MAPPING[domain]
        counts = df[col_name].apply(lambda x: 'Low' if 'Low' in str(x) else ('High' if 'High' in str(x) else 'Some concerns')).value_counts()
        total = len(df)
        if total == 0: total = 1
        data.append([(counts.get('Low', 0)/total)*100, (counts.get('Some concerns', 0)/total)*100, (counts.get('High', 0)/total)*100])
    df_plot = pd.DataFrame(data, columns=['Low', 'Some concerns', 'High'], index=plot_labels)
    fig, ax = plt.subplots(figsize=(10, 5))
    colors = ['#2E7D32', '#F9A825', '#C62828']
    df_plot.plot(kind='barh', stacked=True, color=colors, ax=ax, width=0.7)
    ax.set_xlim(0, 100); ax.set_xlabel("Percentage of Studies (%)"); ax.set_title(f"Risk of Bias Summary: {title}", fontsize=14, fontweight='bold')
    ax.invert_yaxis(); ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), frameon=False)
    ax.spines['top'].set_visible(False); ax.spines['right'].set_visible(False)
    return fig

# --- Sidebar: è¨­å®šèˆ‡ API Key ---
with st.sidebar:
    st.header("ğŸ”‘ è¨­å®š")
    if "GOOGLE_API_KEY" in st.secrets:
        api_key = st.secrets["GOOGLE_API_KEY"]
        st.success("âœ… å·²å¾ Secrets è®€å– API Key")
    else:
        api_key = st.text_input("è«‹è¼¸å…¥æ‚¨çš„ Google Gemini API Key", type="password")
    
    st.divider()
    st.header("1. ç ”ç©¶ä¸»é¡Œè¨­å®š")
    topic = st.text_input("ç ”ç©¶ä¸»é¡Œ", "å­å®®å…§è†œç™Œè¡“å¾Œä½¿ç”¨HRTä¹‹å®‰å…¨æ€§")
    
    if api_key:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.5-pro')

# --- åˆ†é åŠŸèƒ½ ---
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ” PICO æª¢ç´¢", "ğŸ¤– AI è©³ç›¡è©•è®€", "ğŸ“Š æ•¸æ“šèƒå–", "ğŸ“ˆ çµ±è¨ˆåˆ†æ"])

# Tab 1, 2, 3 Logic (å®Œæ•´é‚è¼¯)
with tab1:
    st.header("PICO è¨­å®šèˆ‡ PubMed æœå°‹")
    col1, col2 = st.columns(2)
    with col1:
        p_input = st.text_area("P (Patient)", "Endometrial Neoplasms, Survivors")
        i_input = st.text_area("I (Intervention)", "Hormone Replacement Therapy")
    with col2:
        o_input = st.text_area("O (Outcome)", "Recurrence, Menopause Symptoms")
        t_filter = st.checkbox("æ’é™¤ Review æ–‡ç« ", value=True)
    if st.button("ç”Ÿæˆ PubMed æœå°‹å­—ä¸²"):
        def clean(text): return "(" + " OR ".join([f'"{t.strip()}"' for t in text.split(',') if t.strip()]) + ")"
        q_p, q_i, q_o = clean(p_input), clean(i_input), clean(o_input)
        review_filter = ' NOT "Review"[Publication Type]' if t_filter else ""
        final_query = f"{q_p} AND {q_i} AND {q_o}{review_filter}"
        st.code(final_query, language="text")
        st.markdown(f"ğŸ‘‰ [é»æ­¤å‰å¾€ PubMed æœå°‹](https://pubmed.ncbi.nlm.nih.gov/?term={final_query})")

with tab2:
    st.header("ğŸ¤– AI è‡ªå‹• RoB 2.0 è©•è®€ (å«ç†ç”±)")
    if 'rob_results' not in st.session_state: st.session_state.rob_results = None
    if 'uploaded_files' not in st.session_state: st.session_state.uploaded_files = []
    if 'rob_primary' not in st.session_state: st.session_state.rob_primary = "Menopausal symptoms relief"
    if 'rob_secondary' not in st.session_state: st.session_state.rob_secondary = "Cancer recurrence"
    col_file, col_outcome = st.columns([1, 1])
    with col_file:
        uploaded_files = st.file_uploader("ä¸Šå‚³ PDF æ–‡ç» (æ”¯æ´å¤šæª”)", type="pdf", accept_multiple_files=True, key="rob_uploader")
        if uploaded_files: st.session_state.uploaded_files = uploaded_files
    with col_outcome:
        primary_outcome = st.text_input("ä¸»è¦ Outcome", value=st.session_state.rob_primary, key="rob_primary")
        secondary_outcome = st.text_input("æ¬¡è¦ Outcome", value=st.session_state.rob_secondary, key="rob_secondary")
    if st.button("ğŸš€ é–‹å§‹ RoB è©•è®€") and api_key and uploaded_files:
        progress_bar = st.progress(0); status_text = st.empty(); table_rows = []
        for i, file in enumerate(uploaded_files):
            status_text.text(f"AI æ­£åœ¨è©³è®€ç¬¬ {i+1} ç¯‡ï¼š{file.name} ... (Gemini 2.5 Pro)")
            try:
                pdf_reader = PdfReader(file)
                text_content = ""
                for page in pdf_reader.pages: text_content += page.extract_text()
            except: continue
            prompt = f"""
            ä½ æ˜¯ä¸€ä½åš´è¬¹çš„å¯¦è­‰é†«å­¸å°ˆå®¶ã€‚è«‹æ ¹æ“š RoB 2.0 æŒ‡å¼•è©•è®€ä»¥ä¸‹æ–‡ç»ã€‚
            **è©•ä¼° Outcomeï¼š** 1. {primary_outcome}, 2. {secondary_outcome}
            **è¼¸å‡ºæ ¼å¼ï¼š** ç´”æ–‡å­—è¡¨æ ¼æ•¸æ“šï¼Œä½¿ç”¨ '|' åˆ†éš”ã€‚æ¯ç¯‡æ–‡ç»é‡å°å…©å€‹ Outcome å„è¼¸å‡ºä¸€è¡Œã€‚
            æ ¼å¼ï¼šStudyID | Outcome | D1 | D2 | D3 | D4 | D5 | Overall | Reasoning
            (D1~Overall åªèƒ½å¡« Low, Some concerns, Highã€‚Reasoning è«‹ç”¨ç¹é«”ä¸­æ–‡è©³è¿°ç†ç”±ã€‚)
            **æ–‡ç»å…§å®¹ï¼š** {text_content[:25000]}
            """
            try:
                response = model.generate_content(prompt)
                for line in response.text.strip().split('\n'):
                    if '|' in line and 'StudyID' not in line:
                        cols = [c.strip() for c in line.split('|')]
                        if len(cols) >= 9: table_rows.append(cols[:9])
            except: pass
            progress_bar.progress((i + 1) / len(uploaded_files))
        if table_rows:
            df = pd.DataFrame(table_rows, columns=['Study ID', 'Outcome', 'D1', 'D2', 'D3', 'D4', 'D5', 'Overall', 'Reasoning'])
            st.session_state.rob_results = df.rename(columns=DOMAIN_MAPPING)
            status_text.text("åˆ†æå®Œæˆï¼")
    if st.session_state.rob_results is not None:
        df = st.session_state.rob_results
        st.subheader("ğŸ“‹ è©³ç´°è©•è®€æ•¸æ“šè¡¨"); 
        unique_outcomes = df['Outcome'].unique()
        for outcome in unique_outcomes:
            st.markdown(f"#### ğŸ“Œ Outcome: {outcome}")
            subset_df = df[df['Outcome'] == outcome].reset_index(drop=True).drop(columns=['Outcome'])
            st.dataframe(subset_df, use_container_width=True); st.markdown("---")
        st.subheader("ğŸš¦ RoB 2.0 è¦–è¦ºåŒ–")
        sel_outcome = st.selectbox("é¸æ“‡ Outcome ç¹ªåœ–:", unique_outcomes, key="rob_viz_outcome")
        viz_df = df[df['Outcome'] == sel_outcome]
        if not viz_df.empty:
            c1, c2 = st.columns(2)
            with c1: st.pyplot(plot_traffic_light(viz_df, sel_outcome))
            with c2: st.pyplot(plot_summary_bar(viz_df, sel_outcome))

with tab3:
    st.header("ğŸ“Š æ•¸æ“šèƒå– (Data Extraction)")
    if 'data_extract_results' not in st.session_state: st.session_state.data_extract_results = None
    col_ex_outcome, col_ex_type = st.columns([2, 1])
    with col_ex_outcome:
        outcome_options = [st.session_state.get('rob_primary', ''), st.session_state.get('rob_secondary', '')]
        outcome_options = [opt for opt in outcome_options if opt]
        if not outcome_options: outcome_options = ["è«‹å…ˆè‡³ RoB åˆ†é è¨­å®š Outcome"]
        target_outcome = st.selectbox("æ¬²èƒå–çš„ Outcome (å·²é€£å‹• RoB è¨­å®š)", outcome_options)
    with col_ex_type:
        data_type = st.radio("æ•¸æ“šå‹æ…‹ (Data Type)", ["äºŒå…ƒæ•¸æ“š (Binary: Events/Total)", "é€£çºŒæ•¸æ“š (Continuous: Mean/SD)"])
    if st.button("ğŸ” é–‹å§‹è©³ç´°èƒå–") and api_key and st.session_state.uploaded_files:
        progress_bar = st.progress(0); status_text = st.empty(); extract_rows = []
        files = st.session_state.uploaded_files
        for i, file in enumerate(files):
            status_text.text(f"æ­£åœ¨èƒå–æ•¸æ“šï¼š{file.name} ...")
            try:
                pdf_reader = PdfReader(file)
                text_content = ""
                for page in pdf_reader.pages: text_content += page.extract_text()
            except: continue
            
            base_instruction = f"""
            ä½ æ˜¯ä¸€ä½é†«å­¸æ•¸æ“šåˆ†æå¸«ã€‚è«‹é–±è®€ä»¥ä¸‹æ–‡ç»ï¼Œé‡å° Outcome: "{target_outcome}" æ‰¾å‡ºç›¸é—œæ•¸æ“šèˆ‡ç´°ç¯€ã€‚
            è«‹å‹™å¿…èƒå–ï¼š1. Population (æ—ç¾¤ç‰¹æ€§), 2. Tx_Details (å¯¦é©—çµ„æ²»ç™‚), 3. Ctrl_Details (å°ç…§çµ„æ²»ç™‚)ã€‚
            """
            if "Binary" in data_type:
                prompt = f"""
                {base_instruction}
                ç›®æ¨™æ•¸æ“šå‹æ…‹ï¼šBinary (äºŒå…ƒæ•¸æ“š)ã€‚éœ€èƒå–ï¼šTx_Events, Tx_Total, Ctrl_Events, Ctrl_Totalã€‚
                è¼¸å‡ºæ ¼å¼ï¼šå–®è¡Œç´”æ–‡å­—ï¼Œç”¨ '|' åˆ†éš”ï¼šStudyID | Population | Tx_Details | Ctrl_Details | Tx_Events | Tx_Total | Ctrl_Events | Ctrl_Total
                æ–‡ç»å…§å®¹ï¼š{text_content[:25000]}
                """
                cols_schema = ['Study ID', 'Population', 'Tx Details', 'Ctrl Details', 'Tx Events', 'Tx Total', 'Ctrl Events', 'Ctrl Total']
            else:
                prompt = f"""
                {base_instruction}
                ç›®æ¨™æ•¸æ“šå‹æ…‹ï¼šContinuous (é€£çºŒæ•¸æ“š)ã€‚éœ€èƒå–ï¼šTx_Mean, Tx_SD, Tx_Total, Ctrl_Mean, Ctrl_SD, Ctrl_Totalã€‚
                è¼¸å‡ºæ ¼å¼ï¼šå–®è¡Œç´”æ–‡å­—ï¼Œç”¨ '|' åˆ†éš”ï¼šStudyID | Population | Tx_Details | Ctrl_Details | Tx_Mean | Tx_SD | Tx_Total | Ctrl_Mean | Ctrl_SD | Ctrl_Total
                æ–‡ç»å…§å®¹ï¼š{text_content[:25000]}
                """
                cols_schema = ['Study ID', 'Population', 'Tx Details', 'Ctrl Details', 'Tx Mean', 'Tx SD', 'Tx Total', 'Ctrl Mean', 'Ctrl SD', 'Ctrl Total']
            try:
                response = model.generate_content(prompt)
                for line in response.text.strip().split('\n'):
                    if '|' in line and 'StudyID' not in line:
                        cols = [c.strip() for c in line.split('|')]
                        if len(cols) == len(cols_schema): extract_rows.append(cols)
            except: pass
            progress_bar.progress((i + 1) / len(files))
        if extract_rows:
            st.session_state.data_extract_results = pd.DataFrame(extract_rows, columns=cols_schema)
            st.session_state.current_data_type = data_type 
            status_text.text("èƒå–å®Œæˆï¼")
        else: st.error("èƒå–å¤±æ•—ã€‚")
    if st.session_state.data_extract_results is not None:
        st.dataframe(st.session_state.data_extract_results, use_container_width=True)

# Tab 4 çµ±è¨ˆåˆ†æ (ä½¿ç”¨æ–°ç¹ªåœ–å‡½å¼)
with tab4:
    st.header("ğŸ“ˆ çµ±è¨ˆåˆ†æ (Meta-Analysis & Professional Plots)")
    
    if st.session_state.data_extract_results is not None:
        df_extract = st.session_state.data_extract_results
        data_type = st.session_state.get('current_data_type', "Binary")
        st.info(f"æ­£åœ¨åˆ†æ Outcome: {st.session_state.get('rob_primary', 'Unknown')} ({data_type})")
        
        try:
            ma = MetaAnalysisEngine(df_extract, data_type)
            
            st.subheader("1. ğŸŒ² å°ˆæ¥­æ£®æ—åœ– (GridSpec Aligned)")
            st.pyplot(plot_forest_professional(ma))
            
            col_d1, col_d2 = st.columns(2)
            with col_d1:
                st.subheader("2. ğŸŒªï¸ æ¼æ–—åœ– (Funnel Plot)")
                st.pyplot(plot_funnel(ma))
            with col_d2:
                st.subheader("3. ğŸ“Š Baujat Plot")
                diag_df = ma.get_influence_diagnostics() # é€™è£¡ç¾åœ¨å¯ä»¥æˆåŠŸå‘¼å«äº†
                st.pyplot(plot_baujat(diag_df))

            st.subheader("4. ğŸ“‰ æ•æ„Ÿåº¦åˆ†æ (Leave-One-Out)")
            st.pyplot(plot_leave_one_out_professional(ma))
            
            st.subheader("5. ğŸ” å½±éŸ¿åŠ›è¨ºæ–·çŸ©é™£ (Influence Diagnostics)")
            st.pyplot(plot_influence_diagnostics_grid(ma))
            
            with st.expander("æŸ¥çœ‹è©³ç´°è¨ºæ–·æ•¸å€¼"):
                st.dataframe(ma.influence_df)

        except Exception as e:
            st.error(f"åˆ†æå¤±æ•—: {e}ã€‚è«‹æª¢æŸ¥æ•¸æ“šæ˜¯å¦å®Œæ•´ã€‚")
    else:
        st.warning("âš ï¸ è«‹å…ˆåœ¨ã€Œæ•¸æ“šèƒå–ã€åˆ†é å®Œæˆèƒå–ï¼Œæ‰èƒ½é€²è¡Œçµ±è¨ˆåˆ†æã€‚")
